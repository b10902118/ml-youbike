{"cells":[{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from datetime import datetime, time, timedelta\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_absolute_error\n","from utils import *\n","from median_optimization import optimal_median"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["TRAIN_START = \"2023-10-02 00:00\"\n","TRAIN_END = \"2023-12-10 23:59\"\n","\n","TEST_START = \"2023-10-28 00:00\"\n","TEST_END = \"2023-10-31 23:59\"\n","\n","PUBLIC_START = \"2023-10-21 00:00\"\n","PUBLIC_END = \"2023-10-24 23:59\"\n","\n","PRIVATE_START = \"2023-12-11 00:00\"\n","PRIVARE_END = \"2023-12-17 23:59\""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["with open(\"./cache/small_data_cache.pkl\", \"rb\") as f:\n","    df = pd.read_pickle(f)\n","with open(\"../html.2023.final.data/sno_test_set.txt\") as f:\n","    ntu_snos = [l.strip() for l in f.read().splitlines()]\n","with open(\"./cache/10-03_12_09_rain.pkl\",\"rb\") as f:\n","    rain_df = pd.read_pickle(f)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                datetime  rain\n","0    2023-10-03 01:00:00   0.0\n","1    2023-10-03 02:00:00   0.0\n","2    2023-10-03 03:00:00   0.0\n","3    2023-10-03 04:00:00   0.0\n","4    2023-10-03 05:00:00   0.0\n","...                  ...   ...\n","2227 2023-12-09 20:00:00   0.0\n","2228 2023-12-09 21:00:00   0.0\n","2229 2023-12-09 22:00:00   0.0\n","2230 2023-12-09 23:00:00   0.0\n","2231 2023-12-10 00:00:00   0.0\n","\n","[1632 rows x 2 columns]\n","                    time        sno  tot  sbi act\n","0    2023-10-02 00:00:00  500101001   28   12   1\n","1    2023-10-02 00:01:00  500101001   28   12   1\n","2    2023-10-02 00:02:00  500101001   28   13   1\n","3    2023-10-02 00:03:00  500101001   28   13   1\n","4    2023-10-02 00:04:00  500101001   28   13   1\n","...                  ...        ...  ...  ...  ..\n","1395 2023-12-10 23:15:00  500119091   18    0   1\n","1396 2023-12-10 23:16:00  500119091   18    0   1\n","1397 2023-12-10 23:17:00  500119091   18    0   1\n","1398 2023-12-10 23:18:00  500119091   18    0   1\n","1399 2023-12-10 23:19:00  500119091   18    0   1\n","\n","[9710089 rows x 5 columns]\n"]}],"source":["print(rain_df)\n","print(df)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["ntu_tots = get_tot(df, ntu_snos)\n","# the data looks like this:\n","\"\"\"\n","     datetime               sno      tot   sbi   bemp  act\n","0    2023-10-02 00:00:00  500101001  28.0  12.0  16.0   1\n","1    2023-10-02 00:01:00  500101001  28.0  12.0  16.0   1\n","2    2023-10-02 00:02:00  500101001  28.0  13.0  15.0   1\n","...\n","\"\"\"\n","holidays = [d for d in date_range(start=TRAIN_START, end=PRIVARE_END) if is_holiday(d)]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["df['datehour'] = df['time'].dt.floor(\"H\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["rain_df.rename(columns={'datetime':'datehour'},inplace=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["argument rain to df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       time        sno  tot  sbi act            datehour  rain\n","0       2023-10-02 00:00:00  500101001   28   12   1 2023-10-02 00:00:00   NaN\n","1       2023-10-02 00:01:00  500101001   28   12   1 2023-10-02 00:00:00   NaN\n","2       2023-10-02 00:02:00  500101001   28   13   1 2023-10-02 00:00:00   NaN\n","3       2023-10-02 00:03:00  500101001   28   13   1 2023-10-02 00:00:00   NaN\n","4       2023-10-02 00:04:00  500101001   28   13   1 2023-10-02 00:00:00   NaN\n","...                     ...        ...  ...  ...  ..                 ...   ...\n","9710084 2023-12-10 23:15:00  500119091   18    0   1 2023-12-10 23:00:00   NaN\n","9710085 2023-12-10 23:16:00  500119091   18    0   1 2023-12-10 23:00:00   NaN\n","9710086 2023-12-10 23:17:00  500119091   18    0   1 2023-12-10 23:00:00   NaN\n","9710087 2023-12-10 23:18:00  500119091   18    0   1 2023-12-10 23:00:00   NaN\n","9710088 2023-12-10 23:19:00  500119091   18    0   1 2023-12-10 23:00:00   NaN\n","\n","[9710089 rows x 7 columns]\n"]}],"source":["df = df.merge(rain_df,on='datehour',how='left')\n","print(df)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       time        sno  tot  sbi act            datehour  rain\n","0       2023-10-02 00:00:00  500101001   28   12   1 2023-10-02 00:00:00   0.0\n","1       2023-10-02 00:01:00  500101001   28   12   1 2023-10-02 00:00:00   0.0\n","2       2023-10-02 00:02:00  500101001   28   13   1 2023-10-02 00:00:00   0.0\n","3       2023-10-02 00:03:00  500101001   28   13   1 2023-10-02 00:00:00   0.0\n","4       2023-10-02 00:04:00  500101001   28   13   1 2023-10-02 00:00:00   0.0\n","...                     ...        ...  ...  ...  ..                 ...   ...\n","9710084 2023-12-10 23:15:00  500119091   18    0   1 2023-12-10 23:00:00   0.0\n","9710085 2023-12-10 23:16:00  500119091   18    0   1 2023-12-10 23:00:00   0.0\n","9710086 2023-12-10 23:17:00  500119091   18    0   1 2023-12-10 23:00:00   0.0\n","9710087 2023-12-10 23:18:00  500119091   18    0   1 2023-12-10 23:00:00   0.0\n","9710088 2023-12-10 23:19:00  500119091   18    0   1 2023-12-10 23:00:00   0.0\n","\n","[9710089 rows x 7 columns]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>tot</th>\n","      <th>sbi</th>\n","      <th>datehour</th>\n","      <th>rain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>9710089</td>\n","      <td>9.710089e+06</td>\n","      <td>9.710089e+06</td>\n","      <td>9710089</td>\n","      <td>9.710089e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2023-11-07 15:09:54.800780800</td>\n","      <td>2.579011e+01</td>\n","      <td>7.598337e+00</td>\n","      <td>2023-11-07 14:40:26.217227264</td>\n","      <td>1.582507e-01</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>2023-10-02 00:00:00</td>\n","      <td>5.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>2023-10-02 00:00:00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2023-10-25 03:51:00</td>\n","      <td>1.500000e+01</td>\n","      <td>1.000000e+00</td>\n","      <td>2023-10-25 03:00:00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2023-11-09 05:11:00</td>\n","      <td>2.000000e+01</td>\n","      <td>4.000000e+00</td>\n","      <td>2023-11-09 05:00:00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2023-11-24 07:24:00</td>\n","      <td>3.000000e+01</td>\n","      <td>1.100000e+01</td>\n","      <td>2023-11-24 07:00:00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2023-12-10 23:19:00</td>\n","      <td>9.900000e+01</td>\n","      <td>9.900000e+01</td>\n","      <td>2023-12-10 23:00:00</td>\n","      <td>9.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>NaN</td>\n","      <td>1.701816e+01</td>\n","      <td>1.035669e+01</td>\n","      <td>NaN</td>\n","      <td>6.654206e-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                time           tot           sbi  \\\n","count                        9710089  9.710089e+06  9.710089e+06   \n","mean   2023-11-07 15:09:54.800780800  2.579011e+01  7.598337e+00   \n","min              2023-10-02 00:00:00  5.000000e+00  0.000000e+00   \n","25%              2023-10-25 03:51:00  1.500000e+01  1.000000e+00   \n","50%              2023-11-09 05:11:00  2.000000e+01  4.000000e+00   \n","75%              2023-11-24 07:24:00  3.000000e+01  1.100000e+01   \n","max              2023-12-10 23:19:00  9.900000e+01  9.900000e+01   \n","std                              NaN  1.701816e+01  1.035669e+01   \n","\n","                            datehour          rain  \n","count                        9710089  9.710089e+06  \n","mean   2023-11-07 14:40:26.217227264  1.582507e-01  \n","min              2023-10-02 00:00:00  0.000000e+00  \n","25%              2023-10-25 03:00:00  0.000000e+00  \n","50%              2023-11-09 05:00:00  0.000000e+00  \n","75%              2023-11-24 07:00:00  0.000000e+00  \n","max              2023-12-10 23:00:00  9.000000e+00  \n","std                              NaN  6.654206e-01  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df['rain'].fillna(0,inplace=True)\n","print(df)\n","df.describe()"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["count             15\n","unique            15\n","top       2023-10-03\n","freq               1\n","Name: datehour, dtype: object\n","datehour\n","2023-12-04    15\n","2023-10-04     9\n","2023-12-06     8\n","2023-10-08     4\n","2023-10-20     4\n","2023-10-03     4\n","2023-10-05     4\n","2023-11-16     4\n","2023-10-28     4\n","2023-11-26     3\n","2023-10-06     2\n","2023-11-30     2\n","2023-11-24     1\n","2023-11-12     1\n","2023-11-14     1\n","Name: count, dtype: int64\n"]}],"source":["morning_filter = (df[\"datehour\"].dt.hour >= 7) & (df['datehour'].dt.hour <= 21)\n","rain_hours = df['datehour'][ (df[\"sno\"] == \"500101001\") & morning_filter &(df['rain'] >= 0.5) ].drop_duplicates() # 0.3 for dribble , 0.5 for small rain\n","rain_dates = rain_hours.dt.date.drop_duplicates()\n","\n","print(rain_dates.describe()) # 0.3: 28, 0.5: 15 total:63-62 days\n","\n","date_rain_hour_cnt = rain_hours.dt.date.value_counts()\n","print(date_rain_hour_cnt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter out elements that appear less n times\n","long_rain_dates = rain_dates[rain_dates.isin(date_rain_hour_cnt.index[date_rain_hour_cnt >= 2])]\n","print(long_rain_dates) # 12\n","print(long_rain_dates.describe())\n","rainy_dates = long_rain_dates.array # 12\n","print(rainy_dates)"]},{"cell_type":"markdown","metadata":{},"source":["[ datetime.date(2023, 10, 3),  datetime.date(2023, 10, 4),\n","  datetime.date(2023, 10, 5),  datetime.date(2023, 10, 6),\n","  datetime.date(2023, 10, 8), datetime.date(2023, 10, 20),\n"," datetime.date(2023, 10, 28), datetime.date(2023, 11, 16),\n"," datetime.date(2023, 11, 26), datetime.date(2023, 11, 30),\n","  datetime.date(2023, 12, 4),  datetime.date(2023, 12, 6)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["old_tb = pd.pivot_table(df, index=\"time\", columns=\"sno\", values=\"sbi\")\n","tb = (\n","    pd.pivot_table(df, index=\"time\", columns=\"sno\", values=\"sbi\")\n","    .resample(\"20min\")\n","    .agg(\"first\")\n",")\n","# exclude long holidays\n","tb = tb[~tb.index.to_series().dt.date.isin(long_holiday)]\n","# [] only provides view,so assigning to it cause warning\n","train = tb[tb.index.to_series().dt.date.isin(date_range(TRAIN_START, TRAIN_END))].copy()\n","train.reset_index(names=\"time\", inplace=True)\n","train[\"weekday\"] = train[\"time\"].dt.weekday\n","train.set_index([\"time\", \"weekday\"], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test = tb[tb.index.to_series().dt.date.isin(date_range(TEST_START, TEST_END))]\n","y_test = test.values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result_df = pd.DataFrame(\n","    columns=ntu_snos,\n","    index=pd.MultiIndex.from_product(\n","        [pd.date_range(\"00:00\", \"23:59\", freq=\"20min\").time, [0, 5, 6]],\n","        names=(\"time\", \"weekday\"),\n","    ),\n","    dtype=np.float64,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Ein = 0.0\n","for sno, tot in zip(ntu_snos, ntu_tots):\n","    # sd = station data\n","    sd = train[sno].to_frame()\n","    sd.rename(columns={sno: \"sbi\"}, inplace=True)\n","    sd.reset_index([\"time\", \"weekday\"], inplace=True)\n","    sd[\"date\"] = sd[\"time\"].dt.date\n","    sd[\"time\"] = sd[\"time\"].dt.time\n","    # print(sd)\n","    # exit()\n","    psd = pd.pivot_table(sd, index=[\"date\", \"weekday\"], columns=\"time\", values=\"sbi\")\n","    # sno col have its sbi\n","    # print(psd)\n","    for day in [0, 5, 6]:  # 0 to 6\n","        for t in psd.columns:\n","            # print(t, sno)\n","            sbi, err = 0, 0\n","            # print(\n","            #    psd.loc[psd.index.get_level_values(\"weekday\").isin(range(5)), t].values\n","            # )\n","            if day == 0:  # weekday\n","                sbi, err = optimal_median(\n","                    y_true=psd.loc[\n","                        psd.index.get_level_values(\"weekday\").isin(range(5)), t\n","                    ].values,\n","                    tot=tot,\n","                )\n","            else:\n","                sbi, err = optimal_median(\n","                    y_true=psd.loc[\n","                        psd.index.get_level_values(\"weekday\") == day, t\n","                    ].values,\n","                    tot=tot,\n","                )\n","            Ein += err\n","            # print(f\"{t} sbi:{sbi}   err: {err}\")\n","            result_df.at[(t, day), sno] = sbi\n","            # result_df.at[[t, isholiday], sno] = np.float64(sbi)\n","            # print(result_df.at[t, sno])"]},{"cell_type":"markdown","metadata":{},"source":["print(result_df)<br>\n","we have avg by #date, now by #sno and #time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Ein /= result_df.size\n","print_time_ranges(TRAIN_START, TRAIN_END, TEST_START, TEST_END)\n","print(f\"Ein = {Ein}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def trans(s):\n","    if s in range(5):\n","        return 0\n","    return s"]},{"cell_type":"markdown","metadata":{},"source":["self evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ftr = list(\n","    np.stack([test.index.time, test.index.to_series().dt.weekday.apply(trans)]).T\n",")\n","y_pred = result_df.loc[ftr].values\n","local_test_range = pd.date_range(TEST_START, TEST_END, freq=\"20min\")"]},{"cell_type":"markdown","metadata":{},"source":["print(y_test)<br>\n","print(y_pred)<br>\n","exit()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluation(y_test, y_pred, ntu_tots, local_test_range)"]},{"cell_type":"markdown","metadata":{},"source":["does the same at public test set (2023/10/21 - 2023/10/24)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["public_test_range = pd.date_range(PUBLIC_START, PUBLIC_END, freq=\"20min\")\n","# list makes indexer 1D, or it is an 2D indexer\n","ftr = list(\n","    np.stack([public_test_range.time, np.vectorize(trans)(public_test_range.weekday)]).T\n",")\n","y_public_df = result_df.loc[ftr]\n","print(\"y_public_df Before\")\n","print(y_public_df)"]},{"cell_type":"markdown","metadata":{},"source":["TODO public forward patch<br>\n","Set the initial time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["current_datetime = pd.to_datetime(\"2023-10-20 23:59\")\n","current_time = current_datetime.time()\n","cur_data = old_tb[old_tb.index == current_datetime]\n","print(cur_data)\n","cur = old_tb[old_tb.index.to_series().dt.time == current_time]"]},{"cell_type":"markdown","metadata":{},"source":["Loop to fetch data for the next 20 minutes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["end_datetime = pd.to_datetime(\"2023-10-21 04:40\")\n","next_datetime = current_datetime\n","td = timedelta(minutes=20)\n","total_td = timedelta(minutes=0)\n","while next_datetime <= end_datetime:\n","    # Increment current_time by 20 minutes\n","    next_datetime += td\n","    next_time = next_datetime.time()\n","    total_td += td\n","    # Filter data from old_tb for the current time\n","    nxt = old_tb[old_tb.index.to_series().dt.time == next_time]\n","    diff = nxt - cur.shift(freq=total_td)\n","    mean_diff = pd.pivot_table(diff.mean().reset_index(), columns=\"sno\")\n","    mean_diff.set_index(cur_data.index, inplace=True)\n","    upd = cur_data + mean_diff\n","    # print(upd)\n","    patch_datetime = next_datetime + timedelta(minutes=1)\n","    patch_time = patch_datetime.time()\n","    upd.set_index([[patch_time], [5]], inplace=True)\n","    y_public_df.loc[(patch_time, 5)] = upd\n","# TODO public backward patch\n","current_datetime = pd.to_datetime(\"2023-10-25 00:00\")\n","current_time = current_datetime.time()\n","cur_data = old_tb[old_tb.index == current_datetime]\n","print(cur_data)\n","cur = old_tb[old_tb.index.to_series().dt.time == current_time]"]},{"cell_type":"markdown","metadata":{},"source":["Loop to fetch data for the next 20 minutes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["end_datetime = pd.to_datetime(\"2023-10-24 22:00\")\n","prev_datetime = current_datetime\n","td = timedelta(minutes=20)\n","total_td = timedelta(minutes=0)\n","while prev_datetime >= end_datetime:\n","    # Increment current_time by 20 minutes\n","    prev_datetime -= td\n","    prev_time = prev_datetime.time()\n","    total_td -= td\n","    # Filter data from old_tb for the current time\n","    nxt = old_tb[old_tb.index.to_series().dt.time == prev_time]\n","    diff = nxt - cur.shift(freq=total_td)\n","    mean_diff = pd.pivot_table(diff.mean().reset_index(), columns=\"sno\")\n","    mean_diff.set_index(cur_data.index, inplace=True)  # for add to cur_data only\n","    upd = cur_data + mean_diff\n","    # print(upd)\n","    patch_datetime = prev_datetime  #  + timedelta(minutes=1) # only needed when 23:59\n","    patch_time = patch_datetime.time()\n","    # second index is weekday 10/24 Tue\n","    upd.set_index([[patch_time], [0]], inplace=True)\n","    y_public_df.loc[(patch_time, 0)] = upd"]},{"cell_type":"markdown","metadata":{},"source":["ake value in range"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for col, tot in zip(y_public_df.columns, ntu_tots):\n","    y_public_df[col] = y_public_df[col].clip(lower=0, upper=tot)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"y_public_df After\")\n","print(y_public_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_public_test = y_public_df.values\n","public_test_df = pd.DataFrame(y_public_test, columns=ntu_snos, index=public_test_range)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["private_test_range = pd.date_range(PRIVATE_START, PRIVARE_END, freq=\"20min\")\n","ftr = list(\n","    np.stack(\n","        [private_test_range.time, np.vectorize(trans)(private_test_range.weekday)]\n","    ).T\n",")\n","y_private_df = result_df.loc[ftr]"]},{"cell_type":"markdown","metadata":{},"source":["TODO patch private<br>\n","Set the initial time"]},{"cell_type":"markdown","metadata":{},"source":["\n","<br>\n","current_datetime = pd.to_datetime(\"2023-12-10 23:40\")<br>\n","current_time = current_datetime.time()<br>\n","cur_data = old_tb[old_tb.index == current_datetime]<br>\n","print(cur_data)<br>\n","cur = old_tb[old_tb.index.to_series().dt.time == current_time]<br>\n","# Loop to fetch data for the next 20 minutes<br>\n","end_datetime = pd.to_datetime(\"2023-12-04 03:59\")<br>\n","next_datetime = current_datetime<br>\n","td = timedelta(minutes=20)<br>\n","total_td = timedelta(minutes=0)<br>\n","while next_datetime <= end_datetime:<br>\n","    # Increment current_time by 20 minutes<br>\n","    next_datetime += td<br>\n","    next_time = next_datetime.time()<br>\n","    total_td += td<br>\n","    # Filter data from old_tb for the current time<br>\n","    nxt = old_tb[old_tb.index.to_series().dt.time == next_time]<br>\n","    diff = nxt - cur.shift(freq=total_td)<br>\n","    mean_diff = pd.pivot_table(diff.mean().reset_index(), columns=\"sno\")<br>\n","    mean_diff.set_index(cur_data.index, inplace=True)<br>\n","    upd = cur_data + mean_diff<br>\n","    # print(upd)<br>\n","    patch_datetime = next_datetime + timedelta(minutes=1)<br>\n","    patch_time = patch_datetime.time()<br>\n","    upd.set_index([[patch_time], [0]], inplace=True)<br>\n","    y_private_df.loc[(patch_time, 0)] = upd<br>\n","print(y_private_df)<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_private_test = y_private_df.values\n","private_test_df = pd.DataFrame(\n","    y_private_test, columns=ntu_snos, index=private_test_range\n",")"]},{"cell_type":"markdown","metadata":{},"source":["convert the prediction to the required format"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tmp = pd.concat(\n","    [\n","        public_test_df,\n","        private_test_df,\n","    ]\n",")\n","# reset_index: old index => \"time\" column\n","# id_vars: fixed column like index\n","# var_name: columns.name to \"sno\" column\n","# value_name: value => \"sbi\" column\n","tmp = tmp.reset_index(names=\"time\").melt(\n","    id_vars=\"time\", var_name=\"sno\", value_name=\"sbi\"\n",")\n","out_df = pd.DataFrame(\n","    {\n","        \"id\": (\n","            tmp[\"time\"].dt.strftime(\"%Y%m%d\")\n","            + \"_\"\n","            + tmp[\"sno\"]\n","            + \"_\"\n","            + tmp[\"time\"].dt.strftime(\"%H:%M\")\n","        ),\n","        \"sbi\": tmp[\"sbi\"],\n","    }\n",")\n","out_df.to_csv(\n","    f\"../submission/pub_pri_{datetime.now().strftime('%m-%d-%H-%M')}.csv\", index=False\n",")\n","print(\"csv created\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
