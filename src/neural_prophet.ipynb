{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from neuralprophet import NeuralProphet\n","from datetime import datetime, date, time, timedelta\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_absolute_error\n","from utils import *\n","from median_optimization import optimal_median"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["TRAIN_START = \"2023-10-02 00:00\"\n","TRAIN_END = \"2023-12-17 23:59\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["TEST_START = \"2023-12-01 00:00\"\n","TEST_END = \"2023-12-14 23:59\"\n","test_rain_dates = []"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["PUBLIC_START = \"2023-10-21 00:00\"\n","PUBLIC_END = \"2023-10-24 23:59\"\n","public_rain_dates = []"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["PRIVATE_START = \"2023-12-18 00:00\"\n","PRIVARE_END = \"2023-12-24 23:59\"\n","private_rain_dates = [date(2023, 12, 19), date(2023, 12, 20)]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["with open(\"./cache/small_data_cache.pkl\", \"rb\") as f:\n","    df = pd.read_pickle(f)\n","with open(\"../html.2023.final.data/sno_test_set.txt\") as f:\n","    ntu_snos = [l.strip() for l in f.read().splitlines()]\n","with open(\"./cache/10-03_12_09_rain.pkl\", \"rb\") as f:\n","    rain_df = pd.read_pickle(f)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["ntu_tots = get_tot(df, ntu_snos)\n","# the data looks like this:\n","\"\"\"\n","     datetime               sno      tot   sbi   bemp  act\n","0    2023-10-02 00:00:00  500101001  28.0  12.0  16.0   1\n","1    2023-10-02 00:01:00  500101001  28.0  12.0  16.0   1\n","2    2023-10-02 00:02:00  500101001  28.0  13.0  15.0   1\n","...\n","\"\"\"\n","holidays = [d for d in date_range(start=TRAIN_START, end=PRIVARE_END) if is_holiday(d)]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["df[\"datehour\"] = df[\"time\"].dt.floor(\"H\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["rain_df.rename(columns={\"datetime\": \"datehour\"}, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","argument rain to df"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tot</th>\n","      <th>sbi</th>\n","      <th>rain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1.105241e+07</td>\n","      <td>1.105241e+07</td>\n","      <td>1.105241e+07</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.578958e+01</td>\n","      <td>7.514006e+00</td>\n","      <td>1.390311e-01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.701789e+01</td>\n","      <td>1.029793e+01</td>\n","      <td>6.258437e-01</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>5.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.500000e+01</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.000000e+01</td>\n","      <td>4.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000e+01</td>\n","      <td>1.100000e+01</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>9.900000e+01</td>\n","      <td>9.900000e+01</td>\n","      <td>9.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                tot           sbi          rain\n","count  1.105241e+07  1.105241e+07  1.105241e+07\n","mean   2.578958e+01  7.514006e+00  1.390311e-01\n","std    1.701789e+01  1.029793e+01  6.258437e-01\n","min    5.000000e+00  0.000000e+00  0.000000e+00\n","25%    1.500000e+01  1.000000e+00  0.000000e+00\n","50%    2.000000e+01  4.000000e+00  0.000000e+00\n","75%    3.000000e+01  1.100000e+01  0.000000e+00\n","max    9.900000e+01  9.900000e+01  9.000000e+00"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df = df.merge(rain_df, on=\"datehour\", how=\"left\")\n","df[\"rain\"].fillna(0, inplace=True)\n","# print(df)\n","df.describe()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["morning_filter = (df[\"datehour\"].dt.hour >= 7) & (df[\"datehour\"].dt.hour <= 21)\n","rain_hours = df[\"datehour\"][\n","    (df[\"sno\"] == \"500101001\") & morning_filter & (df[\"rain\"] >= 0.3)\n","].drop_duplicates()  # 0.3 for dribble , 0.5 for small rain\n","rain_dates = rain_hours.dt.date.drop_duplicates()"]},{"cell_type":"markdown","metadata":{},"source":["print(rain_dates.describe()) # 0.3: 28, 0.5: 15 total:63-62 days"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["date_rain_hour_cnt = rain_hours.dt.date.value_counts()\n","# print(date_rain_hour_cnt)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["long_rain_dates = rain_dates[\n","    rain_dates.isin(date_rain_hour_cnt.index[date_rain_hour_cnt >= 7])\n","]\n","# print(long_rain_dates) # 12\n","# print(long_rain_dates.describe())\n","rainy_dates = long_rain_dates.array  # 12\n","# print(rainy_dates)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","[ datetime.date(2023, 10, 3),  datetime.date(2023, 10, 4),<br>\n","  datetime.date(2023, 10, 5),  datetime.date(2023, 10, 6),<br>\n","  datetime.date(2023, 10, 8), datetime.date(2023, 10, 20),<br>\n"," datetime.date(2023, 10, 28), datetime.date(2023, 11, 16),<br>\n"," datetime.date(2023, 11, 26), datetime.date(2023, 11, 30),<br>\n","  datetime.date(2023, 12, 4),  datetime.date(2023, 12, 6)]"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","replace rain to is rainy day"]},{"cell_type":"markdown","metadata":{},"source":["%%"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["df[\"rain\"] = df[\"time\"].dt.date.isin(rainy_dates).astype(np.float64)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","delete rain processing variables"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["del rain_df\n","del morning_filter\n","del rain_hours, rain_dates\n","del date_rain_hour_cnt\n","del long_rain_dates"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","Only one main table. Then always slice from it"]},{"cell_type":"markdown","metadata":{},"source":["%%"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["df.drop(columns=[\"tot\", \"datehour\", \"act\"], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["%%"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["df.rename(columns={\"time\": \"ds\", \"sbi\": \"y\"}, inplace=True)\n","# print(df)"]},{"cell_type":"markdown","metadata":{},"source":["%%<br>\n","df['holiday'] = df['time'].dt.date.isin(holidays)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["holidays_df = pd.DataFrame(\n","    {\n","        \"event\": \"holiday\",\n","        \"ds\": pd.to_datetime(holidays),\n","    }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","Training about 12min (no rain/holiday) 17min (rain/holiday)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import concurrent.futures"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["train = df[df[\"ds\"].dt.date.isin(date_range(TRAIN_START, TRAIN_END))].copy()\n","pred_dfs = {}\n","models = {}"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                      ds  rain  holiday\n","0    2023-12-01 00:00:00   1.0      0.0\n","1    2023-12-01 00:20:00   1.0      0.0\n","2    2023-12-01 00:40:00   1.0      0.0\n","3    2023-12-01 01:00:00   1.0      0.0\n","4    2023-12-01 01:20:00   1.0      0.0\n","...                  ...   ...      ...\n","1003 2023-12-14 22:20:00   0.0      0.0\n","1004 2023-12-14 22:40:00   0.0      0.0\n","1005 2023-12-14 23:00:00   0.0      0.0\n","1006 2023-12-14 23:20:00   0.0      0.0\n","1007 2023-12-14 23:40:00   0.0      0.0\n","\n","[1008 rows x 3 columns]\n"]}],"source":["test_df = pd.DataFrame({\"ds\": pd.date_range(TEST_START, TEST_END, freq=\"20min\")})\n","# test_df['y'] = None\n","test_df[\"rain\"] = test_df[\"ds\"].dt.date.isin(rainy_dates).astype(np.float64)\n","test_df[\"holiday\"] = test_df[\"ds\"].dt.date.isin(holidays).astype(np.float64)\n","print(test_df)"]},{"cell_type":"markdown","metadata":{},"source":["Function to train and predict for a single station"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def train_and_predict(sno):\n","    station_train = (\n","        train[train[\"sno\"] == sno]\n","        .resample(\"5min\", on=\"ds\")\n","        .first()\n","        .dropna()\n","        .reset_index()\n","    )\n","    m = NeuralProphet()\n","    m = m.add_events(\"holiday\")  # , lower_window=0, upper_window=1)\n","    m.add_future_regressor(\"rain\")\n","    station_train = m.create_df_with_events(station_train, holidays_df)  # float 0 1\n","    # print(station_train)\n","    sno_df = df[df[\"sno\"] == sno]\n","    # print(sno_df)\n","    # print(test_df)\n","    sno_test_df = test_df.merge(sno_df[[\"ds\", \"y\"]], on=\"ds\", how=\"left\")\n","    # print(sno_test_df['y'])\n","    m.fit(station_train[[\"ds\", \"y\", \"rain\", \"holiday\"]])\n","\n","    # test_df['y'] = sno_df[sno_df[\"ds\"].isin(test_df[\"ds\"])][\"y\"].values\n","    forecast = m.predict(sno_test_df)\n","    fig = m.plot_components(forecast)\n","    plt.savefig(f\"./prophet_lines/{sno}_components.png\")\n","    plt.close(fig)\n","    return forecast #sno, forecast, m"]},{"cell_type":"markdown","metadata":{},"source":["sno, forecast, m = train_and_predict(ntu_snos[0])"]},{"cell_type":"markdown","metadata":{},"source":["m.plot(forecast)"]},{"cell_type":"markdown","metadata":{},"source":["Train and predict for each station in parallel"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"]},{"name":"stdout","output_type":"stream","text":["Error processing station 500101020: Encountered variable with singular value in training set. Please remove variable.\n"]},{"name":"stderr","output_type":"stream","text":["INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e44f756e75d64e0a9aa0bf58b59c7cfd","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1dd189c04f244e4eb01297bf6253a090","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2510228f79d7489a94768186230865b7","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b29056797984586a6e410c028a76e34","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d42bcbfedce458da335289786a17c8d","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12bf599bb6ef434c864d8cc20c99677f","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28b9bd587a444099b68a0c3a468c3fa2","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ebde37eabdd450fa8fe1f64297811a0","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d74506fc2c084b3191ce5db5ad7720a6","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c454c56cb214feb9f2c216886c0b891","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dc0e85b66fa4a51b3cab5bdb3c85d67","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n","WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.df_utils._infer_frequency) - Major frequency 5T corresponds to 99.909% of the data.\n","INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as 5T\n","INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2e51ebb18384def89c793afd143ccb8","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"458f04e0394b42eba8928d64b3c12ff6","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb17bdd5efc240a1b5173c1bce871ef4","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"affd90b3b6544b12b98c6801f40c626a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"849899039f2844c3a2c111e00d78ae71","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b99cde2ba324931b6ab36178acd155c","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5cda99b34e241cba2e0eaebd88e9f62","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ac384092e6141989e7dd12676497f9e","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98cbe96da26848dd98de98004de6881a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba3da0b066c343d9ab720b8cf8464bd3","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ce63d61ba54d809281d3f04a4a35cf","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93f60fd5a9c2462d933716ae361f13dc","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"407ed70db9cf4305837b91750ded828c","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c41b5137dc4a4d70b3f25fbfd15b7088","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3a7ab6de5ba455aac67fed0fc0baa81","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7892cfd3da48407d9c683ffefde14e32","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37347c5d1e7c49b888f98b8112fe28d4","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49f67af98dc144fa96d2efd347a7923a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4a38b33914149aa96b7d4452b31752a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76acb76568f64e01a0e10dfe984db5a0","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcd874fedbb34673b5ad76dbd58ec54a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1572286db7254580bacf033828cb4c31","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59931951c3594ae9af0b15f21b20a43f","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18153b3a6f12408f8d43e8768a0cb55b","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c58a0483ea1495aaee0e70cfb7b996a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"593fa538e2d94fdb9075ac659687ad3e","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"accdfff0b3694771a07103dc23e6a344","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d8ccf822c99465b98d41cffed40a0c1","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad76bb729c11476bacc4349dd77a2234","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d5177b48e464cb9b49a4c5b853fda72","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11f4742c3d1b48b38a5daa2fe4877b63","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6109d80e4acf48f6b3d4d84d15afd41f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48c6bb4231614c76b4aece04228d59e1","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"462b692923234940b884bd047a8c2dbf","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6db6480c4ea14ffbb04292f933d694ac","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"460b2c1f65394af4ba0aa17ca4a30d81","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a884f5aef8d540d5bfdb02e0218a718f","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"296775bb96d94bfb8fcf04adc929b791","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ab6dde669bd4716b0011bc33c8c59de","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b5b1d4162bd42d8b8a69aaa7c0b56f5","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fc7ed52ba8e4547ae94c74e29f93225","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3171ab824b804c8892f1fc4eb5e10956","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6594f77e115b471d90e11a4ad666d058","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45b2b077b9e34090a16070a520af56f7","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30319131967b4e19825824d35edd1d43","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f69a7e093ea4194a465209a1396a04a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efe43c5fdc37463bb40ca19705479327","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51304cd9efca4588a024a4631a6262ae","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c62f02f3314456b7253f1c9a357bce","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eac17d06c6744e15ac3febb63f8390d0","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b35db22fde284aaf85dff7e21df912cc","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7da8890c56364cf1b40f527630fdc91b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"335e076d25b24651b3a5f15d6e825d4a","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70b1da236bbf49dab345e27db8cc0e18","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a236dc6eb1d74605a44db3774d821d10","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c28d668b7ff6478aaed20e87b4b57b9d","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35240f6d49524ef8a9b770b9330b0a9a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88ac12f08d1e4204bda1d776f89a5c29","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53f9aaef82ce426eae88720b5cd0223a","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c1ad4218e334dcb9b783751c5b629c8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0652689373c74f0baa234d11c1e80bf8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e02c217e603b4baaa92eb39c97e7379d","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d5c431130ad4488bbc5eda2b3517f00","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d623d238c13441eb93c63e99ddce459c","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c68fb25566c495a9898b63828aa31ab","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f42bcdbe3a484a04a1d5b739cb772f73","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"959a993931fd4cc393a44edca7d39fdb","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c09ab9bb05d4822bfda70398dc7dbab","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a436d7eaf2d745f7978114a28299f9ad","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e529494a4424cfa8cbb7788b0d1d2e9","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fe61e7dee1f4b879afbe14cc4222ca9","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2a71d499b224c42a5c98d68f952540c","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n","INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 86\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a338a277ee4d4a3bb7cf4c6ba5b5f2ac","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae45e46acdb44a9f8369c760a425fe39","version_major":2,"version_minor":0},"text/plain":["Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"879cdc3b0b344bafa389900766c18093","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13a90af16be64e60bca2593c71835177","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"837c87e098ce4b26af8201c826e39b27","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a98889300244495eb2bea379831b3dc2","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7a62d722e08477aa4905aec96a0e36b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c70dfbcb4cc64488934da260f61d747e","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dab2217831e1464eaa248903471f07db","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c6bc26238434828a63178e34d3606d5","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f368000ffb84ba08d20586e37fb9641","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf361430e04d4c70a0a3b7671426037f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2523f901a5d4c8a9e0d9a20786c2de6","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03ccc2f2e14948378ae9b4e329acf4ce","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1a26aeef5b34eec8d785d069adde7d8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f2d4a5820074e9f965233487b1b45bb","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b4ac97e18454a6ab770a82e28d1610b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff42aeab99a24d4a97c3ed4e8f4052cf","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b57de8c43a34f1790f9f3df1e60789f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c345dec479194e2f850a8825cf9601b4","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66c9eadfd7ab43cb9978fcd96870def8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7057e6fdd85408096c39a46f069b7d2","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0a0aa0f870a4b39960133044fb8940e","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"330381338391495ab0e2cf7daf15f745","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"851e3795f2f944428fab058f3a00b022","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"408429974c774156a77ec4cb3df863fc","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4cda23474444cb3bd0c999383958f1c","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7087e21fc4194915987dfc539d32587d","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa2695723b5744d4b6f1baf40bd1c311","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9615b2ddd0d7429fab2dc9034586b660","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df84fed21cb044e8a56f4acb9609f92c","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a9daf759b9c4ad1918ace349846c77e","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0360b52be7f04bd08b176f765f3348cc","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f19d279c422a4bc0af527849f0f22f43","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"296a306986d1452a82192883e5de2a5b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46ac868250ab44569f5d0a7e73f9a216","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"763ca149fae043e484003304f7cef267","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Resource temporarily unavailable (src/thread.cpp:269)\n"]},{"name":"stdout","output_type":"stream","text":["Error processing station 500101001: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101002: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101003: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101004: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101005: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101006: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101007: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101008: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101009: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101010: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101013: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101014: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101015: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101018: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101019: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101021: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101022: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101023: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101024: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101025: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101026: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101027: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101028: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101029: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101030: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101031: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101032: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101033: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101034: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101035: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101036: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101037: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101038: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101039: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101040: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101041: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101042: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101091: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101092: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101093: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101094: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101114: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101115: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101123: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101166: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101175: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101176: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101181: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101184: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101185: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101188: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101189: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101190: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101191: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101193: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101199: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101209: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101216: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500101219: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500105066: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500106002: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500106003: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500106004: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119043: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119044: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119045: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119046: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119047: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119048: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119049: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119050: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119051: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119052: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119053: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119054: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119055: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119056: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119057: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119058: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119059: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119060: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119061: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119062: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119063: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119064: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119065: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119066: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119067: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119068: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119069: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119070: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119071: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119072: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119074: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119075: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119076: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119077: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119078: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119079: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119080: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119081: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119082: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119083: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119084: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119085: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119086: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119087: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119088: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119089: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119090: A process in the process pool was terminated abruptly while the future was running or pending.\n","Error processing station 500119091: A process in the process pool was terminated abruptly while the future was running or pending.\n"]}],"source":["with concurrent.futures.ProcessPoolExecutor(max_workers=40) as executor:  # seems to be single thread\n","    # Submit jobs for each station\n","    future_to_sno = {executor.submit(train_and_predict, sno): sno for sno in ntu_snos}\n","\n","    # Retrieve results as they become available\n","    for future in concurrent.futures.as_completed(future_to_sno):\n","        sno = future_to_sno[future]\n","        try:\n","            #result_sno, forecast_sno, model_sno = future.result()\n","            forecast_sno = future.result()\n","            pred_dfs[sno] = forecast_sno\n","            #models[result_sno] = model_sno\n","        except Exception as e:\n","            print(f\"Error processing station {sno}: {e}\")"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","print(pred_dfs[ntu_snos[2]])"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","pred_df = pred_dfs[ntu_snos[0]]<br>\n","m = models[ntu_snos[0]]<br>\n","fig = m.plot_components(pred_df)<br>\n","plt.savefig(f\"./prophet_lines/{ntu_snos[0]}_components.png\")<br>\n","plt.close(fig)<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_range = pd.date_range(TEST_START, TEST_END, freq=\"20min\")\n","test_len = len(list(test_range))\n","test_df = df[df[\"ds\"].isin(test_range)]\n","test_tb = (\n","    pd.pivot_table(test_df, index=\"ds\", columns=\"sno\", values=\"y\")\n","    .resample(\"20min\")\n","    .first()\n","    .bfill()\n","    .ffill()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = np.empty([test_len, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["errors = {}\n","for sno, tot in zip(ntu_snos, ntu_tots):\n","    pred_df = pred_dfs[sno]\n","    #m = models[sno]\n","    #fig = m.plot_components(pred_df)\n","    #plt.savefig(f\"./prophet_lines/{sno}_components.png\")\n","    #plt.close(fig)\n","    pred_df[\"yhat\"].clip(lower=0, upper=tot, inplace=True)\n","    pred = pred_df[\"yhat\"].to_numpy()\n","    y_pred = np.column_stack((y_pred, pred))\n","\n","    # TODO E_in\n","    ans = test_tb[sno]\n","    # print(ans.shape, pred_df.shape)\n","    err = error(ans.to_numpy(), pred, np.full(test_len, tot))\n","    errors[sno] = err\n","    ax = pred_df.plot(x=\"ds\", y=\"yhat\", figsize=(20, 6), title=f\"score: {err}\")\n","    ans.plot(ax=ax, x=\"ds\", y=\"y\")\n","    plt.savefig(f\"./neural_prophet_lines/{sno}.png\")\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"./neural_prophet_lines/results.txt\", \"w\") as f:\n","    for e in sorted(errors.items(), key=lambda x: x[1]):\n","        f.write(f\"{e[0]}: {e[1]}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","Self evaluation (Test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test = test_tb[test_tb.index.to_series().dt.date.isin(date_range(TEST_START, TEST_END))]\n","y_test = test.values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_time_ranges(TRAIN_START, TRAIN_END, TEST_START, TEST_END)\n","assert y_test.shape == y_pred.shape, \"test pred shape not matched\"\n","# y_pred = y_pred[:,1:]\n","print(y_test.shape)  # (1008, 112)\n","print(y_pred.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluation(y_test, y_pred, ntu_tots, test_range)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","<br>\n","all sunny \\<br>\n","MAE:  0.13275823190272154 \\<br>\n","Score:  0.24003751756886713<br>\n","<br>\n","all data \\<br>\n","MAE:  0.1229537906365303 \\<br>\n","Score:  0.21939612130515754<br>\n","<br>\n","rain+sunny \\<br>\n","MAE:  0.12230290642321821 \\<br>\n","Score:  0.2167087889314868<br>\n"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","does the same at public test set (2023/10/21 - 2023/10/24)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","public_test_range = pd.date_range(PUBLIC_START, PUBLIC_END, freq=\"20min\")<br>\n","# list makes indexer 1D, or it is an 2D indexer<br>\n","ftr = list(<br>\n","    np.stack([[False]*(4*72),public_test_range.time, public_test_range.weekday]).T<br>\n",")<br>\n","y_public_df = result_df.loc[ftr]<br>\n","#print(\"y_public_df Before\")<br>\n","#print(y_public_df)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","Check public"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","#print(\"y_public_df After\")<br>\n","#print(y_public_df)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","for col, tot in zip(y_public_df.columns, ntu_tots):<br>\n","    y_public_df[col] = y_public_df[col].clip(lower=0, upper=tot)<br>\n","y_public_test = y_public_df.values<br>\n","public_test_df = pd.DataFrame(y_public_test, columns=ntu_snos, index=public_test_range)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","private_test_range = pd.date_range(PRIVATE_START, PRIVARE_END, freq=\"20min\")<br>\n","ftr = list(<br>\n","    np.stack(<br>\n","        [[d in private_rain_dates for d in private_test_range.date],private_test_range.time, private_test_range.weekday]<br>\n","    ).T<br>\n",")<br>\n","y_private_df = result_df.loc[ftr]"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","# TODO patch private<br>\n","# Set the initial time<br>\n","current_datetime = pd.to_datetime(\"2023-12-17 22:40\")<br>\n","current_time = current_datetime.time()<br>\n","cur_data = tb[tb.index == current_datetime]<br>\n","print(cur_data)<br>\n","cur = tb[tb.index.to_series().dt.time == current_time]<br>\n","<br>\n","# Loop to fetch data for the next 20 minutes<br>\n","end_datetime = pd.to_datetime(\"2023-12-18 04:00\")<br>\n","next_datetime = current_datetime + timedelta(minutes=60)<br>\n","td = timedelta(minutes=20)<br>\n","total_td = timedelta(minutes=60)<br>\n","while next_datetime <= end_datetime:<br>\n","    # Increment current_time by 20 minutes<br>\n","    next_datetime += td<br>\n","    next_time = next_datetime.time()<br>\n","    total_td += td<br>\n","    # Filter data from tb for the current time<br>\n","    nxt = tb[tb.index.to_series().dt.time == next_time]<br>\n","    diff = nxt - cur.shift(freq=total_td)<br>\n","    mean_diff = pd.pivot_table(diff.mean().reset_index(), columns=\"sno\")<br>\n","    mean_diff.set_index(cur_data.index, inplace=True)<br>\n","    upd = cur_data + mean_diff<br>\n","    print(upd)<br>\n","    patch_datetime = next_datetime<br>\n","    patch_time = patch_datetime.time()<br>\n","    print(patch_time)<br>\n","    upd.set_index([[patch_time], [0]], inplace=True)<br>\n","    y_private_df.loc[(patch_time, 0)] = upd"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","if y_private_df.isnull().values.any():<br>\n","    print(\"DataFrame contains NaN values.\")<br>\n","print(y_private_df)"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","assert not y_private_df.isnull().values.any(), \"private contains null\"<br>\n","for col, tot in zip(y_private_df.columns, ntu_tots):<br>\n","    y_private_df[col] = y_private_df[col].clip(lower=0, upper=tot)<br>\n","y_private_test = y_private_df.values<br>\n","private_test_df = pd.DataFrame(<br>\n","    y_private_test, columns=ntu_snos, index=private_test_range<br>\n",")"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","tmp = pd.concat(<br>\n","    [<br>\n","        public_test_df,<br>\n","        private_test_df,<br>\n","    ]<br>\n",")<br>\n","# reset_index: old index => \"time\" column<br>\n","# id_vars: fixed column like index<br>\n","# var_name: columns.name to \"sno\" column<br>\n","# value_name: value => \"sbi\" column<br>\n","tmp = tmp.reset_index(names=\"time\").melt(<br>\n","    id_vars=\"time\", var_name=\"sno\", value_name=\"sbi\"<br>\n",")<br>\n","out_df = pd.DataFrame(<br>\n","    {<br>\n","        \"id\": (<br>\n","            tmp[\"time\"].dt.strftime(\"%Y%m%d\")<br>\n","            + \"_\"<br>\n","            + tmp[\"sno\"]<br>\n","            + \"_\"<br>\n","            + tmp[\"time\"].dt.strftime(\"%H:%M\")<br>\n","        ),<br>\n","        \"sbi\": tmp[\"sbi\"],<br>\n","    }<br>\n",")<br>\n","out_df.to_csv(<br>\n","    f\"../submission/pub_pri_{datetime.now().strftime('%m-%d-%H-%M')}.csv\", index=False<br>\n",")<br>\n","print(\"csv created\")"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","TODO patch private<br><br>\n","Set the initial time"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","<br>\n","<br><br>\n","current_datetime = pd.to_datetime(\"2023-12-10 23:40\")<br><br>\n","current_time = current_datetime.time()<br><br>\n","cur_data = old_tb[old_tb.index == current_datetime]<br><br>\n","print(cur_data)<br><br>\n","cur = old_tb[old_tb.index.to_series().dt.time == current_time]<br><br>\n","# Loop to fetch data for the next 20 minutes<br><br>\n","end_datetime = pd.to_datetime(\"2023-12-04 03:59\")<br><br>\n","next_datetime = current_datetime<br><br>\n","td = timedelta(minutes=20)<br><br>\n","total_td = timedelta(minutes=0)<br><br>\n","while next_datetime <= end_datetime:<br><br>\n","    # Increment current_time by 20 minutes<br><br>\n","    next_datetime += td<br><br>\n","    next_time = next_datetime.time()<br><br>\n","    total_td += td<br><br>\n","    # Filter data from old_tb for the current time<br><br>\n","    nxt = old_tb[old_tb.index.to_series().dt.time == next_time]<br><br>\n","    diff = nxt - cur.shift(freq=total_td)<br><br>\n","    mean_diff = pd.pivot_table(diff.mean().reset_index(), columns=\"sno\")<br><br>\n","    mean_diff.set_index(cur_data.index, inplace=True)<br><br>\n","    upd = cur_data + mean_diff<br><br>\n","    # print(upd)<br><br>\n","    patch_datetime = next_datetime + timedelta(minutes=1)<br><br>\n","    patch_time = patch_datetime.time()<br><br>\n","    upd.set_index([[patch_time], [0]], inplace=True)<br><br>\n","    y_private_df.loc[(patch_time, 0)] = upd<br><br>\n","print(y_private_df)<br><br>\n"]},{"cell_type":"markdown","metadata":{},"source":["%% [markdown]<br>\n","convert the prediction to the required format"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
